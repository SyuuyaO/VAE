{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effbde31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syudi\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 指定されたプロシージャが見つかりません。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "C:\\Users\\syudi\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 指定されたプロシージャが見つかりません。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ResNet_VAE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 151\u001b[0m\n\u001b[0;32m    148\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset\u001b[38;5;241m=\u001b[39mtest_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Create model\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m resnet_vae \u001b[38;5;241m=\u001b[39m \u001b[43mResNet_VAE\u001b[49m(fc_hidden1\u001b[38;5;241m=\u001b[39mCNN_fc_hidden1, fc_hidden2\u001b[38;5;241m=\u001b[39mCNN_fc_hidden2, drop_p\u001b[38;5;241m=\u001b[39mdropout_p, CNN_embed_dim\u001b[38;5;241m=\u001b[39mCNN_embed_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m model_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(resnet_vae\u001b[38;5;241m.\u001b[39mparameters())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ResNet_VAE' is not defined"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ResNet_VAE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 151\u001b[0m\n\u001b[0;32m    148\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset\u001b[38;5;241m=\u001b[39mtest_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Create model\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m resnet_vae \u001b[38;5;241m=\u001b[39m \u001b[43mResNet_VAE\u001b[49m(fc_hidden1\u001b[38;5;241m=\u001b[39mCNN_fc_hidden1, fc_hidden2\u001b[38;5;241m=\u001b[39mCNN_fc_hidden2, drop_p\u001b[38;5;241m=\u001b[39mdropout_p, CNN_embed_dim\u001b[38;5;241m=\u001b[39mCNN_embed_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m model_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(resnet_vae\u001b[38;5;241m.\u001b[39mparameters())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ResNet_VAE' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as pltd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# EncoderCNN architecture\n",
    "CNN_fc_hidden1, CNN_fc_hidden2 = 1024, 1024\n",
    "CNN_embed_dim = 256     # latent dim extracted by 2D CNN\n",
    "res_size = 224        # ResNet image size\n",
    "dropout_p = 0.2       # dropout probability\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 20        # training epochs\n",
    "batch_size = 50\n",
    "learning_rate = 1e-3\n",
    "log_interval = 10   # interval for displaying training info\n",
    "\n",
    "# save model\n",
    "save_model_path = './results_cifar10'\n",
    "\n",
    "def check_mkdir(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # MSE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    MSE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return MSE + KLD\n",
    "\n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    # set model as training mode\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    all_y, all_z, all_mu, all_logvar = [], [], [], []\n",
    "    N_count = 0   # counting total trained sample in one epoch\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        # distribute data to device\n",
    "        X, y = X.to(device), y.to(device).view(-1, )\n",
    "        N_count += X.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        X_reconst, z, mu, logvar = model(X)  # VAE\n",
    "        loss = loss_function(X_reconst, X, mu, logvar)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        all_y.extend(y.data.cpu().numpy())\n",
    "        all_z.extend(z.data.cpu().numpy())\n",
    "        all_mu.extend(mu.data.cpu().numpy())\n",
    "        all_logvar.extend(logvar.data.cpu().numpy())\n",
    "\n",
    "        # show information\n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
    "\n",
    "    all_y = np.stack(all_y, axis=0)\n",
    "    all_z = np.stack(all_z, axis=0)\n",
    "    all_mu = np.stack(all_mu, axis=0)\n",
    "    all_logvar = np.stack(all_logvar, axis=0)\n",
    "\n",
    "    # save Pytorch models of best record\n",
    "    torch.save(model.state_dict(), os.path.join(save_model_path, 'model_epoch{}.pth'.format(epoch + 1)))  # save motion_encoder\n",
    "    torch.save(optimizer.state_dict(), os.path.join(save_model_path, 'optimizer_epoch{}.pth'.format(epoch + 1)))      # save optimizer\n",
    "    print(\"Epoch {} model saved!\".format(epoch + 1))\n",
    "\n",
    "    return X_reconst.data.cpu().numpy(), all_y, all_z, all_mu, all_logvar, losses\n",
    "\n",
    "\n",
    "def validation(model, device, optimizer, test_loader):\n",
    "    # set model as testing mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    all_y, all_z, all_mu, all_logvar = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            # distribute data to device\n",
    "            X, y = X.to(device), y.to(device).view(-1, )\n",
    "            X_reconst, z, mu, logvar = model(X)\n",
    "\n",
    "            loss = loss_function(X_reconst, X, mu, logvar)\n",
    "            test_loss += loss.item()  # sum up batch loss\n",
    "\n",
    "            all_y.extend(y.data.cpu().numpy())\n",
    "            all_z.extend(z.data.cpu().numpy())\n",
    "            all_mu.extend(mu.data.cpu().numpy())\n",
    "            all_logvar.extend(logvar.data.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    all_y = np.stack(all_y, axis=0)\n",
    "    all_z = np.stack(all_z, axis=0)\n",
    "    all_mu = np.stack(all_mu, axis=0)\n",
    "    all_logvar = np.stack(all_logvar, axis=0)\n",
    "\n",
    "    # show information\n",
    "    print('\\nTest set ({:d} samples): Average loss: {:.4f}\\n'.format(len(test_loader.dataset), test_loss))\n",
    "    return X_reconst.data.cpu().numpy(), all_y, all_z, all_mu, all_logvar, test_loss\n",
    "\n",
    "\n",
    "# Detect devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "\n",
    "# Data loading parameters\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "# transform = transforms.Compose([transforms.Resize([res_size, res_size]),\n",
    "#                                 transforms.ToTensor(),\n",
    "#                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize([res_size, res_size]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0])])\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(data_path) if f.endswith('.png')]  # 適宜拡張子を変更\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data_path, self.image_files[idx])\n",
    "        image = cv2.imread(img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = np.array(image).astype(np.float32) / 255.0  # 正規化\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# 訓練データとテストデータのパス\n",
    "train_data_path = 'C:\\\\Users\\\\syudi\\\\neuralnet\\\\bubblejet\\\\bubblejet\\\\datasetVAEtrain'\n",
    "test_data_path = 'C:\\\\Users\\\\syudi\\\\neuralnet\\\\bubblejet\\\\bubblejet\\\\datasetVAEtest'\n",
    "\n",
    "# ImageFolderを使ってデータをロード\n",
    "train_dataset = datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_data_path, transform=transform)\n",
    "\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Data loader (input pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create model\n",
    "resnet_vae = ResNet_VAE(fc_hidden1=CNN_fc_hidden1, fc_hidden2=CNN_fc_hidden2, drop_p=dropout_p, CNN_embed_dim=CNN_embed_dim).to(device)\n",
    "\n",
    "print(\"Using\", torch.cuda.device_count(), \"GPU!\")\n",
    "model_params = list(resnet_vae.parameters())\n",
    "optimizer = torch.optim.Adam(model_params, lr=learning_rate)\n",
    "\n",
    "\n",
    "# record training process\n",
    "epoch_train_losses = []\n",
    "epoch_test_losses = []\n",
    "check_mkdir(save_model_path)\n",
    "\n",
    "# start training\n",
    "for epoch in range(epochs):\n",
    "    # train, test model\n",
    "    X_reconst_train, y_train, z_train, mu_train, logvar_train, train_losses = train(log_interval, resnet_vae, device, train_loader, optimizer, epoch)\n",
    "    X_reconst_test, y_test, z_test, mu_test, logvar_test, epoch_test_loss = validation(resnet_vae, device, optimizer, valid_loader)\n",
    "\n",
    "    # save results\n",
    "    epoch_train_losses.append(train_losses)\n",
    "    epoch_test_losses.append(epoch_test_loss)\n",
    "\n",
    "    # save all train test results\n",
    "    A = np.array(epoch_train_losses)\n",
    "    C = np.array(epoch_test_losses)\n",
    "    \n",
    "    np.save(os.path.join(save_model_path, 'ResNet_VAE_training_loss.npy'), A)\n",
    "    np.save(os.path.join(save_model_path, 'y_cifar10_train_epoch{}.npy'.format(epoch + 1)), y_train)\n",
    "    np.save(os.path.join(save_model_path, 'z_cifar10_train_epoch{}.npy'.format(epoch + 1)), z_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
