{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c15544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openpyxl\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def load_latent_variables_from_excel(excel_path):\n",
    "    \"\"\"Excelファイルから潜在変数データとファイル名を読み込む関数\"\"\"\n",
    "    latent_vectors = []\n",
    "    file_names = []\n",
    "    \n",
    "    # Excelファイルを開く\n",
    "    wb = openpyxl.load_workbook(excel_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    # Excelの各行からファイル名と潜在変数ベクトルを読み込む\n",
    "    for row in ws.iter_rows(min_row=1, values_only=True):\n",
    "        file_name = row[0]  # 一列目がファイル名\n",
    "        latent_vector = np.array(list(map(float, row[1].split(','))))  # 潜在変数をカンマ区切りで読み込む\n",
    "        file_names.append(file_name)\n",
    "        latent_vectors.append(latent_vector)\n",
    "\n",
    "    return file_names, np.array(latent_vectors)\n",
    "\n",
    "def find_top_k_similar(file_names, latent_vectors, new_latent, k=5):\n",
    "    \"\"\"既存の潜在変数と新たに生成した潜在変数とのユークリッド距離を計算し、上位k個を取得する\"\"\"\n",
    "    distances = []\n",
    "    \n",
    "    # 既存の潜在変数と新しい潜在変数のユークリッド距離を計算\n",
    "    for i, latent_vector in enumerate(latent_vectors):\n",
    "        dist = np.linalg.norm(latent_vector - new_latent)  # ユークリッド距離を計算\n",
    "        distances.append((i, dist))  # 各ベクトルのインデックスと距離を保存\n",
    "\n",
    "    # 距離が小さい順にソート\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "\n",
    "    # 上位k個を返す（ファイル名、距離）\n",
    "    return [(file_names[idx], dist) for idx, dist in distances[:k]]\n",
    "\n",
    "# Excelファイルから潜在変数をロード\n",
    "excel_path = 'latent_variables_z.xlsx'\n",
    "file_names, latent_vectors = load_latent_variables_from_excel(excel_path)\n",
    "\n",
    "# 新しく生成した潜在変数 (例: バッチサイズが1で1つの潜在変数ベクトル)\n",
    "new_latent_vector = np.random.rand(256)  # 256次元の潜在変数の例\n",
    "\n",
    "# ユークリッド距離が最も小さい上位5つを取得\n",
    "top_5_similar = find_top_k_similar(file_names, latent_vectors, new_latent_vector, k=5)\n",
    "\n",
    "# 結果を表示\n",
    "for file_name, dist in top_5_similar:\n",
    "    print(f\"File: {file_name}, Distance: {dist}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e13536",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 次元削減（Dimensionality Reduction）\n",
    "高次元空間での距離計算は計算量が大きくなりがちです。次元削減を行うことで、計算量を減らすことができます。代表的な方法には以下があります：\n",
    "\n",
    "PCA（主成分分析）: 高次元データをより少ない次元に圧縮し、情報の損失を最小限に抑える方法。潜在変数の次元を削減して距離計算を行うことができます。\n",
    "t-SNE や UMAP: データを2次元や3次元に投影し、距離関係を保持したまま次元を削減する手法。ただし、PCAに比べて計算コストが高い場合があります。\n",
    "2. KD-Tree や Ball Tree を使った探索\n",
    "空間内の近傍点を効率的に探索するためのデータ構造です。ユークリッド距離などの距離計算を効率化するために使われます。\n",
    "\n",
    "KD-Tree: データの空間を軸に沿って再帰的に分割することで、最近傍探索を高速化します。ただし、高次元（100次元以上）では効率が落ちる場合があります。\n",
    "Ball Tree: KD-Treeが高次元で効率が悪い場合に有効なデータ構造。空間を球体に分割し、距離計算を高速化します。\n",
    "scikit-learn の NearestNeighbors クラスでこれらを簡単に実装できます：\n",
    "\n",
    "python\n",
    "コードをコピーする\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# 潜在変数の行列（例: latent_vectors）に基づきKD-Treeを構築\n",
    "nbrs = NearestNeighbors(n_neighbors=5, algorithm='kd_tree').fit(latent_vectors)\n",
    "\n",
    "# 新たに生成された潜在変数に対して最近傍探索を実行\n",
    "distances, indices = nbrs.kneighbors([new_latent])\n",
    "これにより、近傍点探索の計算量を効率化できます。\n",
    "\n",
    "3. Approximate Nearest Neighbors (ANN)\n",
    "厳密な最近傍探索ではなく、多少誤差が許される場合には、近似最近傍探索（ANN）を使うことができます。これにより、計算時間を大幅に短縮できます。\n",
    "\n",
    "Faiss: Facebookが開発した、非常に効率的な近似最近傍検索ライブラリ。特にベクトルの探索に特化しており、GPUでの高速化も可能です。\n",
    "python\n",
    "コードをコピーする\n",
    "import faiss\n",
    "\n",
    "# 潜在変数の行列をFAISS用に準備\n",
    "index = faiss.IndexFlatL2(latent_vectors.shape[1])  # L2距離（ユークリッド距離）を使用\n",
    "index.add(latent_vectors)  # ベクトルをインデックスに追加\n",
    "\n",
    "# 新しい潜在変数に対して最近傍探索を実行\n",
    "distances, indices = index.search(new_latent.reshape(1, -1), k=5)\n",
    "Faissは非常に高速な探索が可能で、特に大規模データに対して効果的です。\n",
    "\n",
    "4. ブロック化やバッチ処理\n",
    "距離計算をバッチ化することで、複数の潜在変数間の距離計算を並列処理やGPUを使って効率化できます。通常のループではなく、行列演算やバッチ処理を用いることで、計算時間を短縮できます。\n",
    "例えば、NumPyやPyTorchを使ってユークリッド距離の計算をベクトル化することで、1回の演算で全ての距離を計算できます：\n",
    "python\n",
    "コードをコピーする\n",
    "# 全ての潜在変数ベクトルとの距離を一気に計算\n",
    "distances = np.linalg.norm(latent_vectors - new_latent, axis=1)\n",
    "\n",
    "\n",
    "5. GPUの活用\n",
    "PyTorchやTensorFlowなどのフレームワークを使って、距離計算をGPUで行うことも一つの手法です。特にベクトルの比較が大量に必要な場合、GPUの並列処理能力が有効です。\n",
    "python\n",
    "コードをコピーする\n",
    "latent_vectors_tensor = torch.tensor(latent_vectors).to(device)  # GPUに転送\n",
    "new_latent_tensor = torch.tensor(new_latent).to(device)\n",
    "distances = torch.norm(latent_vectors_tensor - new_latent_tensor, dim=1)  # GPUで計算\n",
    "\n",
    "\n",
    "6. ハッシュベースの検索\n",
    "ハッシュテーブルを使って近傍点探索を高速化する方法もあります。\n",
    "\n",
    "Locality-Sensitive Hashing (LSH): ベクトルの近さを反映したハッシュ関数を使い、計算量を削減するアルゴリズムです。特に大規模なデータセットで有効です。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
